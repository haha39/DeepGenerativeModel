{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 設定設備（GPU 或 CPU）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 Autoencoder 模型\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),  # 把 28x28 影像展平成 784 維向量\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim),  # 壓縮到 latent_dim 維度\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 784),\n",
    "            nn.Sigmoid()  # 確保輸出範圍在 [0,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon.view(-1, 1, 28, 28)  # 轉回 28x28 影像格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=32):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "\n",
    "        # **Encoder（編碼器）：使用卷積層**\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),  # 輸入: (1, 28, 28) -> (16, 14, 14)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), # (16, 14, 14) -> (32, 7, 7)\n",
    "            nn.BatchNorm2d(32),  # 加入 Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),  # 攤平成一維\n",
    "            nn.Linear(32 * 7 * 7, latent_dim)  # 壓縮到 latent_dim\n",
    "        )\n",
    "\n",
    "        # **Decoder（解碼器）：使用轉置卷積層（ConvTranspose2d）**\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32 * 7 * 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (32, 7, 7)),  # 恢復空間結構\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1), # (32,7,7) -> (16,14,14)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  # (16,14,14) -> (1,28,28)\n",
    "            nn.Sigmoid()  # 確保輸出值在 0~1 之間\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  訓練函數\n",
    "def train_autoencoder(model, train_loader, num_epochs=10):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()  # 使用 MSE 作為損失函數\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for images, _ in train_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, images)  # 計算 MSE 誤差\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  計算誤差（MSE 和 L1）\n",
    "def evaluate_autoencoder(model, data_loader):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    mse_loss = nn.MSELoss()\n",
    "    l1_loss = nn.L1Loss()\n",
    "    \n",
    "    total_mse, total_l1 = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, _ in data_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            total_mse += mse_loss(outputs, images).item()\n",
    "            total_l1 += l1_loss(outputs, images).item()\n",
    "    \n",
    "    avg_mse = total_mse / len(data_loader)\n",
    "    avg_l1 = total_l1 / len(data_loader)\n",
    "    \n",
    "    return avg_mse, avg_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示重建影像（4x4 網格）\n",
    "def show_reconstructed_images(model, data_loader, num_images=16):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    images, _ = next(iter(data_loader))  # 取一批數據\n",
    "    images = images[:num_images].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "\n",
    "    # 轉換為 numpy 格式\n",
    "    images = images.cpu().numpy().squeeze()\n",
    "    outputs = outputs.cpu().numpy().squeeze()\n",
    "\n",
    "        # 顯示原始影像\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axes[i, j].imshow(images[i * 4 + j], cmap='gray')\n",
    "            axes[i, j].axis('off')\n",
    "    plt.suptitle(\"Original Images\")\n",
    "    plt.show()\n",
    "\n",
    "    # 顯示重建影像\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axes[i, j].imshow(outputs[i * 4 + j], cmap='gray')\n",
    "            axes[i, j].axis('off')\n",
    "    plt.suptitle(\"Reconstructed Images\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下載並載入 MNIST 數據集\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  訓練並評估 Autoencoder（測試不同 latent_dim）\n",
    "latent_dims = [64, 32, 4]\n",
    "\n",
    "for latent_dim in latent_dims:\n",
    "    print(f\"\\nTraining Autoencoder with latent dimension = {latent_dim}\")\n",
    "    # autoencoder = Autoencoder(latent_dim)\n",
    "    autoencoder = ConvAutoencoder(latent_dim)\n",
    "    train_autoencoder(autoencoder, train_loader, num_epochs=20)\n",
    "\n",
    "    train_mse, train_l1 = evaluate_autoencoder(autoencoder, train_loader)\n",
    "    test_mse, test_l1 = evaluate_autoencoder(autoencoder, test_loader)\n",
    "\n",
    "    print(f\"Training MSE: {train_mse:.4f}, L1 Loss: {train_l1:.4f}\")\n",
    "    print(f\"Testing  MSE: {test_mse:.4f}, L1 Loss: {test_l1:.4f}\")\n",
    "\n",
    "    # 顯示重建影像\n",
    "    print(\"Training Images Reconstruction:\")\n",
    "    show_reconstructed_images(autoencoder, train_loader)\n",
    "\n",
    "    print(\"Testing Images Reconstruction:\")\n",
    "    show_reconstructed_images(autoencoder, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下載並載入 FashionMNIST 數據集\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  訓練並評估 Autoencoder（測試不同 latent_dim）\n",
    "latent_dims = [64, 32, 4]\n",
    "\n",
    "for latent_dim in latent_dims:\n",
    "    print(f\"\\nTraining Autoencoder with latent dimension = {latent_dim}\")\n",
    "    # autoencoder = Autoencoder(latent_dim)\n",
    "    autoencoder = ConvAutoencoder(latent_dim)\n",
    "    train_autoencoder(autoencoder, train_loader, num_epochs=20)\n",
    "\n",
    "    train_mse, train_l1 = evaluate_autoencoder(autoencoder, train_loader)\n",
    "    test_mse, test_l1 = evaluate_autoencoder(autoencoder, test_loader)\n",
    "\n",
    "    print(f\"Training MSE: {train_mse:.4f}, L1 Loss: {train_l1:.4f}\")\n",
    "    print(f\"Testing  MSE: {test_mse:.4f}, L1 Loss: {test_l1:.4f}\")\n",
    "\n",
    "    # 顯示重建影像\n",
    "    print(\"Training Images Reconstruction:\")\n",
    "    show_reconstructed_images(autoencoder, train_loader)\n",
    "\n",
    "    print(\"Testing Images Reconstruction:\")\n",
    "    show_reconstructed_images(autoencoder, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
