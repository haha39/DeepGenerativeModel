{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "呱呱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 2-gram 统计信息 ===\n",
      "不同的 2-gram 组合数量: 39\n",
      "最常出现的 2-gram: (' ',)，总计 169892 次\n",
      "最可能出现的下一个字符: [('t', 24243), ('a', 13939), ('s', 12733)]\n",
      "生成文本:  wamfar larit tl ltrthy,\n",
      "winch tom f illyotheybrth n l ary lls:\n",
      "llat inongormay!\n",
      "i wies 'l iour, it intull,\n",
      "\n",
      "ould! f cher noutmater g,\n",
      "thounche ce bsayothas feata byedsoe\n",
      "lla veft:\n",
      "swoocke by, f\n",
      "h is s\n",
      "\n",
      "=== 3-gram 统计信息 ===\n",
      "不同的 3-gram 组合数量: 832\n",
      "最常出现的 3-gram: ('e', ' ')，总计 27965 次\n",
      "最可能出现的下一个字符: [('t', 3640), ('s', 2122), ('a', 2085)]\n",
      "生成文本: e youll rat, sixt--ad eyer, gin vosty 's sour, wicke en thell cou to nexcus,\n",
      "thatis'd;\n",
      "fie?\n",
      "\n",
      "houtly inged unt dee i'll nobeedward:\n",
      "youch hisay, sout i'll.\n",
      "workmanow loore; le;\n",
      "gene nothospare my noblent\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import random\n",
    "import requests\n",
    "\n",
    "# 下载 wiki_text.txt\n",
    "def download_wiki_text(file_path):\n",
    "    url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "    response = requests.get(url)\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(response.text)\n",
    "\n",
    "# 读取数据集\n",
    "def load_text(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().lower()  # 统一转换为小写，减少重复字符影响\n",
    "    return text\n",
    "\n",
    "# 统计 n-gram 频率\n",
    "def build_ngram_counts(text, n):\n",
    "    ngram_counts = collections.defaultdict(collections.Counter)\n",
    "    \n",
    "    for i in range(len(text) - n):\n",
    "        prefix = tuple(text[i:i+n-1])  # 前 n-1 个字符\n",
    "        next_char = text[i+n-1]        # 预测的目标字符\n",
    "        ngram_counts[prefix][next_char] += 1\n",
    "    \n",
    "    return ngram_counts\n",
    "\n",
    "# 统计不同 n-gram 的数量\n",
    "def count_unique_ngrams(ngram_counts):\n",
    "    return len(ngram_counts)\n",
    "\n",
    "# 找出出现最多的 n-gram\n",
    "def most_frequent_ngram(ngram_counts):\n",
    "    return max(ngram_counts.items(), key=lambda x: sum(x[1].values()))\n",
    "\n",
    "# 生成文本\n",
    "def generate_text(ngram_counts, start_seq, length=100):\n",
    "    generated_text = list(start_seq)\n",
    "    \n",
    "    for _ in range(length):\n",
    "        prefix = tuple(generated_text[-(len(start_seq)):])\n",
    "        if prefix in ngram_counts:\n",
    "            next_char = random.choices(\n",
    "                list(ngram_counts[prefix].keys()), \n",
    "                weights=ngram_counts[prefix].values()\n",
    "            )[0]\n",
    "            generated_text.append(next_char)\n",
    "        else:\n",
    "            break  # 若遇到未知的前缀，则停止生成\n",
    "    \n",
    "    return ''.join(generated_text)\n",
    "\n",
    "# 主程序\n",
    "file_path = \"wiki_text.txt\"\n",
    "download_wiki_text(file_path)\n",
    "text = load_text(file_path)\n",
    "\n",
    "for n in [2, 3]:\n",
    "    print(f\"\\n=== {n}-gram 统计信息 ===\")\n",
    "    ngram_counts = build_ngram_counts(text, n)\n",
    "    print(f\"不同的 {n}-gram 组合数量: {count_unique_ngrams(ngram_counts)}\")\n",
    "    \n",
    "    most_frequent, occurrences = most_frequent_ngram(ngram_counts)\n",
    "    print(f\"最常出现的 {n}-gram: {most_frequent}，总计 {sum(occurrences.values())} 次\")\n",
    "    print(f\"最可能出现的下一个字符: {occurrences.most_common(3)}\")\n",
    "    \n",
    "    # 从最频繁的 n-gram 生成文本\n",
    "    generated_text = generate_text(ngram_counts, most_frequent, length=200)\n",
    "    print(f\"生成文本: {generated_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.0629205393468344\n",
      "Epoch 2, Loss: 2.005397035963688\n",
      "Epoch 3, Loss: 1.9958393552009464\n",
      "Epoch 4, Loss: 1.9905648772421578\n",
      "Epoch 5, Loss: 1.9873847461961567\n",
      "Epoch 6, Loss: 1.9851459673930123\n",
      "Epoch 7, Loss: 1.9832827137141482\n",
      "Epoch 8, Loss: 1.9818782862485318\n",
      "Epoch 9, Loss: 1.981221349025391\n",
      "Epoch 10, Loss: 1.9799752683849654\n",
      "\n",
      "生成文本: ther youredmus:\n",
      "anightem;\n",
      "areme\n",
      "of of houg to mentrathrome\n",
      "thend forciell rand that gaorm\n",
      "my crovospet--and strese\n",
      "thfuld lon,\n",
      "burets the raw or pet,\n",
      "wel the ser spard, as of spe oare your leadairst ge \n",
      "\n",
      "生成文本: ory: grew-oxshan of as wart nius:\n",
      "cary ard i tend lit the tar to prall by a gives you th shark, brantelf to bood ne ind\n",
      "thall'd cult seloves, to to horrathomad theit surs we itiesbuy theredwely to sover\n",
      "\n",
      "生成文本: ard: tain, ber'd:\n",
      "shourat the ame, reed parris ta:\n",
      "isay, uponot dinsworticit ord:\n",
      "haris prot he laiv:\n",
      "i wer lif not the frowbat mang remaduke you fi, ch he taray, hattlevess but.\n",
      "\n",
      "ve kin of hich do her'\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import random\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 定义数据集类\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, n, char_to_idx):\n",
    "        self.n = n\n",
    "        self.char_to_idx = char_to_idx\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for i in range(len(text) - n):\n",
    "            self.data.append([char_to_idx[c] for c in text[i:i+n-1]])\n",
    "            self.labels.append(char_to_idx[text[i+n-1]])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx]), torch.tensor(self.labels[idx])\n",
    "    \n",
    "\n",
    "# 定义 1D-CNN 模型\n",
    "class CNNTextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_filters, kernel_size, hidden_dim):\n",
    "        super(CNNTextGenerator, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.conv1d = nn.Conv1d(embed_dim, num_filters, kernel_size, padding=1)\n",
    "        self.fc1 = nn.Linear(num_filters * (n-1), hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).permute(0, 2, 1)  # 调整维度适应 Conv1d\n",
    "        x = torch.relu(self.conv1d(x)).flatten(start_dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# 训练模型\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "\n",
    "# 生成文本\n",
    "def generate_cnn_text(model, start_seq, idx_to_char, char_to_idx, length=100, temperature=1.0):\n",
    "    model.eval()\n",
    "    generated_text = list(start_seq)\n",
    "\n",
    "    for _ in range(length):\n",
    "        input_seq = torch.tensor([[char_to_idx[c] for c in generated_text[-(n-1):]]], device=device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq)\n",
    "            output = output.squeeze(0) / temperature  # 调整温度参数\n",
    "            probabilities = torch.softmax(output, dim=0)\n",
    "            next_char_idx = torch.multinomial(probabilities, num_samples=1).item()  # 采样\n",
    "            generated_text.append(idx_to_char[next_char_idx])\n",
    "\n",
    "    return ''.join(generated_text)\n",
    "\n",
    "\n",
    "\n",
    "# 主程序\n",
    "file_path = \"shakespeare.txt\"\n",
    "download_wiki_text(file_path)\n",
    "text = load_text(file_path)\n",
    "\n",
    "\n",
    "# 构建字符索引\n",
    "chars = sorted(set(text))\n",
    "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
    "idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
    "vocab_size = len(chars)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n = 3  # 选择 n-gram 的值\n",
    "\n",
    "dataset = TextDataset(text, n, char_to_idx)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 初始化模型\n",
    "model = CNNTextGenerator(vocab_size, embed_dim=32, num_filters=64, kernel_size=3, hidden_dim=128).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=10)\n",
    "\n",
    "# 生成文本\n",
    "start_seq = \"th\"\n",
    "generated_text = generate_cnn_text(model, start_seq, idx_to_char, char_to_idx, length=200)\n",
    "print(\"\\n生成文本:\", generated_text)\n",
    "\n",
    "start_seq = \"or\"\n",
    "generated_text = generate_cnn_text(model, start_seq, idx_to_char, char_to_idx, length=200)\n",
    "print(\"\\n生成文本:\", generated_text)\n",
    "\n",
    "start_seq = \"ar\"\n",
    "generated_text = generate_cnn_text(model, start_seq, idx_to_char, char_to_idx, length=200)\n",
    "print(\"\\n生成文本:\", generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
